{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T07:00:03.681577Z","iopub.execute_input":"2023-09-21T07:00:03.682587Z","iopub.status.idle":"2023-09-21T07:00:04.196679Z","shell.execute_reply.started":"2023-09-21T07:00:03.682535Z","shell.execute_reply":"2023-09-21T07:00:04.195288Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/speech-based-classification-layer-9/valid.csv\n/kaggle/input/speech-based-classification-layer-9/train.csv\n/kaggle/input/speech-based-classification-layer-9/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Imports\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport joblib\n\nimport math\nimport seaborn as sns\nimport warnings                   # To ignore the warnings\nimport pandas as pd\nimport numpy as np          # For mathematical calculations\nimport matplotlib.pyplot as plt  # For plotting graphs\nfrom datetime import datetime    # To access datetime\nfrom pandas import Series        # To work on series\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support\n\nfrom xgboost import XGBClassifier\n\n# import RandomizedSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:06:27.242296Z","iopub.execute_input":"2023-09-21T07:06:27.243047Z","iopub.status.idle":"2023-09-21T07:06:29.287535Z","shell.execute_reply.started":"2023-09-21T07:06:27.242980Z","shell.execute_reply":"2023-09-21T07:06:29.285754Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Data importing","metadata":{}},{"cell_type":"code","source":"train_layer_9 = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-9/train.csv\")\nvalid_layer_9 = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-9/valid.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:06:32.795177Z","iopub.execute_input":"2023-09-21T07:06:32.796661Z","iopub.status.idle":"2023-09-21T07:06:45.593300Z","shell.execute_reply.started":"2023-09-21T07:06:32.796603Z","shell.execute_reply":"2023-09-21T07:06:45.592060Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Test Dataset","metadata":{}},{"cell_type":"code","source":"test_layer_9 = pd.read_csv(\"/kaggle/input/speech-based-classification-layer-9/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:06:47.815187Z","iopub.execute_input":"2023-09-21T07:06:47.815633Z","iopub.status.idle":"2023-09-21T07:06:48.175049Z","shell.execute_reply.started":"2023-09-21T07:06:47.815600Z","shell.execute_reply":"2023-09-21T07:06:48.173436Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_layer_9.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:08:47.188126Z","iopub.execute_input":"2023-09-21T07:08:47.188495Z","iopub.status.idle":"2023-09-21T07:08:47.218742Z","shell.execute_reply.started":"2023-09-21T07:08:47.188467Z","shell.execute_reply":"2023-09-21T07:08:47.217302Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n0   1   0.013112   0.130904   0.020284   0.063018  -0.034321  -0.073516   \n1   2   0.005934   0.138592  -0.007000   0.055925  -0.021927  -0.084788   \n2   3  -0.067210   0.078710  -0.044344   0.101248  -0.074331  -0.088951   \n3   4  -0.005678   0.060703   0.033954   0.068771  -0.039923  -0.186583   \n4   5  -0.076360   0.061095  -0.004938   0.066692  -0.040454  -0.005141   \n\n   feature_7  feature_8  feature_9  ...  feature_759  feature_760  \\\n0  -0.030659  -0.064994   0.024153  ...     0.037803     0.241121   \n1   0.013339   0.060811  -0.011344  ...    -0.098701     0.042921   \n2   0.074616   0.007231   0.021091  ...     0.029569     0.053370   \n3   0.014921   0.020791   0.017441  ...    -0.095406     0.018405   \n4  -0.003213   0.025721   0.083558  ...    -0.003129     0.045479   \n\n   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n0     0.079949    -0.186099    -0.096718     0.126006    -0.023069   \n1     0.018571    -0.114785    -0.105186     0.059050     0.021443   \n2     0.096232    -0.369018    -0.066708    -0.003730    -0.063339   \n3    -0.018047    -0.080393    -0.114030     0.048255     0.033839   \n4     0.057146    -0.194466     0.000739     0.018702     0.013192   \n\n   feature_766  feature_767  feature_768  \n0     0.190374     0.146516     0.038047  \n1     0.013027     0.046826    -0.026682  \n2    -0.044497    -0.024363    -0.042594  \n3     0.035026    -0.047988    -0.038252  \n4    -0.038486     0.033358    -0.038452  \n\n[5 rows x 769 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>feature_759</th>\n      <th>feature_760</th>\n      <th>feature_761</th>\n      <th>feature_762</th>\n      <th>feature_763</th>\n      <th>feature_764</th>\n      <th>feature_765</th>\n      <th>feature_766</th>\n      <th>feature_767</th>\n      <th>feature_768</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.013112</td>\n      <td>0.130904</td>\n      <td>0.020284</td>\n      <td>0.063018</td>\n      <td>-0.034321</td>\n      <td>-0.073516</td>\n      <td>-0.030659</td>\n      <td>-0.064994</td>\n      <td>0.024153</td>\n      <td>...</td>\n      <td>0.037803</td>\n      <td>0.241121</td>\n      <td>0.079949</td>\n      <td>-0.186099</td>\n      <td>-0.096718</td>\n      <td>0.126006</td>\n      <td>-0.023069</td>\n      <td>0.190374</td>\n      <td>0.146516</td>\n      <td>0.038047</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.005934</td>\n      <td>0.138592</td>\n      <td>-0.007000</td>\n      <td>0.055925</td>\n      <td>-0.021927</td>\n      <td>-0.084788</td>\n      <td>0.013339</td>\n      <td>0.060811</td>\n      <td>-0.011344</td>\n      <td>...</td>\n      <td>-0.098701</td>\n      <td>0.042921</td>\n      <td>0.018571</td>\n      <td>-0.114785</td>\n      <td>-0.105186</td>\n      <td>0.059050</td>\n      <td>0.021443</td>\n      <td>0.013027</td>\n      <td>0.046826</td>\n      <td>-0.026682</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-0.067210</td>\n      <td>0.078710</td>\n      <td>-0.044344</td>\n      <td>0.101248</td>\n      <td>-0.074331</td>\n      <td>-0.088951</td>\n      <td>0.074616</td>\n      <td>0.007231</td>\n      <td>0.021091</td>\n      <td>...</td>\n      <td>0.029569</td>\n      <td>0.053370</td>\n      <td>0.096232</td>\n      <td>-0.369018</td>\n      <td>-0.066708</td>\n      <td>-0.003730</td>\n      <td>-0.063339</td>\n      <td>-0.044497</td>\n      <td>-0.024363</td>\n      <td>-0.042594</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>-0.005678</td>\n      <td>0.060703</td>\n      <td>0.033954</td>\n      <td>0.068771</td>\n      <td>-0.039923</td>\n      <td>-0.186583</td>\n      <td>0.014921</td>\n      <td>0.020791</td>\n      <td>0.017441</td>\n      <td>...</td>\n      <td>-0.095406</td>\n      <td>0.018405</td>\n      <td>-0.018047</td>\n      <td>-0.080393</td>\n      <td>-0.114030</td>\n      <td>0.048255</td>\n      <td>0.033839</td>\n      <td>0.035026</td>\n      <td>-0.047988</td>\n      <td>-0.038252</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>-0.076360</td>\n      <td>0.061095</td>\n      <td>-0.004938</td>\n      <td>0.066692</td>\n      <td>-0.040454</td>\n      <td>-0.005141</td>\n      <td>-0.003213</td>\n      <td>0.025721</td>\n      <td>0.083558</td>\n      <td>...</td>\n      <td>-0.003129</td>\n      <td>0.045479</td>\n      <td>0.057146</td>\n      <td>-0.194466</td>\n      <td>0.000739</td>\n      <td>0.018702</td>\n      <td>0.013192</td>\n      <td>-0.038486</td>\n      <td>0.033358</td>\n      <td>-0.038452</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 769 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_train = train_layer_9.copy().drop(\n    columns=[\"label_1\", \"label_2\", \"label_3\", \"label_4\"]\n)\nx_valid = valid_layer_9.copy().drop(\n    columns=[\"label_1\", \"label_2\", \"label_3\", \"label_4\"]\n)\nx_feature_names = [\"feature_\" + str(i) for i in range(1, 769)]\n\nid_train = train_layer_9[\"label_1\"].to_frame()\nage_train = train_layer_9[\"label_2\"].to_frame()  # id has NaN\ngender_train = train_layer_9[\"label_3\"].to_frame()\naccent_train = train_layer_9[\"label_4\"].to_frame()  # Accent has bias to 6\n\nid_valid = valid_layer_9[\"label_1\"].to_frame()\nage_valid = valid_layer_9[\"label_2\"].to_frame()\ngender_valid = valid_layer_9[\"label_3\"].to_frame()\naccent_valid = valid_layer_9[\"label_4\"].to_frame()\n\n# Scaling using RobustScaler\nscaler_robust = RobustScaler()\nscaler_robust.fit(x_train)\n\nx_train_scaled = pd.DataFrame(scaler_robust.transform(x_train), columns=x_feature_names)\nx_valid_scaled = pd.DataFrame(scaler_robust.transform(x_valid), columns=x_feature_names)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:06:57.167404Z","iopub.execute_input":"2023-09-21T07:06:57.167917Z","iopub.status.idle":"2023-09-21T07:06:58.671751Z","shell.execute_reply.started":"2023-09-21T07:06:57.167874Z","shell.execute_reply":"2023-09-21T07:06:58.670423Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Test Dataset","metadata":{}},{"cell_type":"code","source":"x_test = test_layer_9.copy().drop(\n    columns=[\"ID\"]\n)\nx_test_scaled = pd.DataFrame(scaler_robust.transform(x_test), columns=x_feature_names)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:09:26.701978Z","iopub.execute_input":"2023-09-21T07:09:26.702470Z","iopub.status.idle":"2023-09-21T07:09:26.730109Z","shell.execute_reply.started":"2023-09-21T07:09:26.702406Z","shell.execute_reply":"2023-09-21T07:09:26.728819Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Support Functions","metadata":{}},{"cell_type":"code","source":"def validate_model(model, x_valid, y_valid):\n    y_pred = model.predict(x_valid)\n    accuracy = accuracy_score(y_valid, y_pred)\n    print(\"Accuracy: \", accuracy)\n    cm = confusion_matrix(y_valid, y_pred)\n    print(\"Confusion matrix: \")\n    print(cm)\n    print(\"Precision, recall, f1-score: \")\n    prfs_ = precision_recall_fscore_support(\n        y_valid, y_pred, average=\"weighted\")\n    return prfs_, cm\n\ndef do_pca(train, valid, variance: float = None, n_components: int = None):\n    pca_obj = PCA(n_components=0.95, svd_solver=\"full\")\n    if variance:\n        pca_obj = PCA(n_components=variance, svd_solver=\"full\")\n    elif n_components:\n        pca_obj = PCA(n_components=n_components)\n    pca_obj.fit(train)\n    n_components = pca_obj.components_.shape[0]\n\n    x_train = pd.DataFrame(\n        pca_obj.transform(train),\n        columns=[\"feature_pca_\" + str(i) for i in range(1, n_components + 1)],\n    )\n    x_valid = pd.DataFrame(\n        pca_obj.transform(valid),\n        columns=[\"feature_pca_\" + str(i) for i in range(1, n_components + 1)],\n    )\n\n    return x_train, x_valid, n_components, pca_obj\n\ndef fit_and_score(classifier_models, x_train, x_valid, y_train, y_valid):\n    \"\"\"\n    Fits and evaluates given classifier models.\n    classifier_models : a dict of different Scikit-Learn classifier models\n    x_train : training data (no labels)\n    x_valid : validation data (no labels)\n    y_train : training labels\n    y_valid : validation labels\n    \"\"\"\n    # Set random seed\n    np.random.seed(42)\n    # Make a dictionary to keep model scores\n    classifier_model_scores = {}\n    # Loop through classifier_models\n    for name, model in classifier_models.items():\n        print(f\"Fitting {name}...\")\n        # Fit the model to the data\n        model.fit(x_train, y_train)\n        # Evaluate the model and append its score to classifier_model_scores\n        classifier_model_scores[name] = model.score(x_valid, y_valid)\n        print(\"Done fitting and scoring model.\")\n    return classifier_model_scores\n\ndef tune_hyperparameters(classifier_models, grid, x_train, x_valid, y_train, y_valid):\n    \"\"\"\n    Fits and evaluates given classifier models.\n    classifier_models : a dict of different Scikit-Learn classifier models\n    grid : a dict of hyperparameters to tune\n    x_train : training data (no labels)\n    x_valid : validation data (no labels)\n    y_train : training labels\n    y_valid : validation labels\n    \"\"\"\n    # Set random seed\n    np.random.seed(42)\n    # Make a dictionary to keep model scores\n    classifier_model_scores = {}\n    trained_searches = {}\n    # Loop through classifier_models\n    for name, model in classifier_models.items():\n        # Setup random hyperparameter search for model\n        rs_model = RandomizedSearchCV(\n            estimator=model,\n            param_distributions=grid,\n            n_iter=20,\n            cv=5,\n            verbose=3,\n            random_state=42,\n            n_jobs=-1,\n        )\n        # Fit random hyperparameter search model\n        fileName = name + \"_rs_model\" + \".pkl\"\n        rs_model.fit(x_train, y_train)\n        # Export rs_model using joblib\n        joblib.dump(rs_model, fileName)\n        trained_searches[name] = rs_model\n\n        # Evaluate the model and append its score to classifier_model_scores\n        classifier_model_scores[name] = rs_model.score(x_valid, y_valid)\n        print(\"classifier model scores\", classifier_model_scores)\n    return trained_searches","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:09:32.148995Z","iopub.execute_input":"2023-09-21T07:09:32.149474Z","iopub.status.idle":"2023-09-21T07:09:32.185725Z","shell.execute_reply.started":"2023-09-21T07:09:32.149440Z","shell.execute_reply":"2023-09-21T07:09:32.184600Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Label 01","metadata":{}},{"cell_type":"code","source":"id_data_train_cat = pd.concat([x_train_scaled, id_train], axis=1)\nid_data_valid_cat = pd.concat([x_valid_scaled, id_valid], axis=1)\n\n# Remove rows with null values\nid_data_cleaned_train_cat = id_data_train_cat.dropna()\nid_data_cleaned_valid_cat = id_data_valid_cat.dropna()\n\n# Separate X and y again\nid_x_train_cat = id_data_cleaned_train_cat.drop(columns=[\"label_1\"])\nid_y_train_cat = id_data_cleaned_train_cat[\"label_1\"]\nid_x_valid_cat = id_data_cleaned_valid_cat.drop(columns=[\"label_1\"])\nid_y_valid_cat = id_data_cleaned_valid_cat[\"label_1\"].to_frame()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:09:35.760659Z","iopub.execute_input":"2023-09-21T07:09:35.761143Z","iopub.status.idle":"2023-09-21T07:09:36.084381Z","shell.execute_reply.started":"2023-09-21T07:09:35.761110Z","shell.execute_reply":"2023-09-21T07:09:36.083004Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Test Dataset","metadata":{}},{"cell_type":"code","source":"\n# Separate X and y again\nid_x_test_cat = x_test_scaled","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:10:46.254806Z","iopub.execute_input":"2023-09-21T07:10:46.255514Z","iopub.status.idle":"2023-09-21T07:10:46.260858Z","shell.execute_reply.started":"2023-09-21T07:10:46.255470Z","shell.execute_reply":"2023-09-21T07:10:46.259818Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"id_initial = SVC()\nid_initial.fit(id_x_train_cat, id_y_train_cat)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:10:51.757066Z","iopub.execute_input":"2023-09-21T07:10:51.757555Z","iopub.status.idle":"2023-09-21T07:13:33.782900Z","shell.execute_reply.started":"2023-09-21T07:10:51.757507Z","shell.execute_reply":"2023-09-21T07:13:33.781453Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"precision_recall_fscore_svc_initial, cm_initial = validate_model(id_initial, id_x_valid_cat, id_y_valid_cat)\n\nprint(\"Precision, Recall and F1 Score:\", precision_recall_fscore_svc_initial)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T12:58:39.914836Z","iopub.execute_input":"2023-09-20T12:58:39.916055Z","iopub.status.idle":"2023-09-20T12:58:58.250567Z","shell.execute_reply.started":"2023-09-20T12:58:39.916003Z","shell.execute_reply":"2023-09-20T12:58:58.249413Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy:  0.9466666666666667\nConfusion matrix: \n[[12  0  0 ...  0  0  0]\n [ 0  9  0 ...  0  0  0]\n [ 0  0 11 ...  0  0  0]\n ...\n [ 0  0  0 ... 20  0  0]\n [ 0  0  0 ...  0 10  0]\n [ 0  0  0 ...  0  1  9]]\nPrecision, recall, f1-score: \nPrecision, Recall and F1 Score: (0.9535477330661541, 0.9466666666666667, 0.9474071091104397, None)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_predictions = id_initial.predict(id_x_test_cat)\nprint(test_predictions[:10])\npd.DataFrame(test_predictions, columns=[\"label_1\"]).to_csv(\"id_test_predictions.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:26:53.640783Z","iopub.execute_input":"2023-09-21T07:26:53.641284Z","iopub.status.idle":"2023-09-21T07:27:17.069683Z","shell.execute_reply.started":"2023-09-21T07:26:53.641243Z","shell.execute_reply":"2023-09-21T07:27:17.068147Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[26 18 16  7 58 46  7 22 29 26]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### PCA","metadata":{}},{"cell_type":"code","source":"id_x_train_pca_85, id_x_valid_pca_85, id_n_components, id_pca_cat = do_pca(\n    id_x_train_cat, id_x_valid_cat, n_components=70\n)\nprint(\"Number of components: \", id_n_components)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:46:25.472757Z","iopub.execute_input":"2023-09-21T07:46:25.473288Z","iopub.status.idle":"2023-09-21T07:46:30.658392Z","shell.execute_reply.started":"2023-09-21T07:46:25.473248Z","shell.execute_reply":"2023-09-21T07:46:30.656830Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Number of components:  70\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Test Dataset","metadata":{}},{"cell_type":"code","source":"id_x_test_pca_85 = pd.DataFrame(\n    id_pca_cat.transform(id_x_test_cat),\n    columns=[\"feature_pca_\" + str(i) for i in range(1, id_n_components + 1)],\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T07:47:24.122522Z","iopub.execute_input":"2023-09-21T07:47:24.122998Z","iopub.status.idle":"2023-09-21T07:47:24.149509Z","shell.execute_reply.started":"2023-09-21T07:47:24.122964Z","shell.execute_reply":"2023-09-21T07:47:24.147703Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"id_final = SVC()\nid_final.fit(id_x_train_pca_85, id_y_train_cat)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T12:59:02.062590Z","iopub.execute_input":"2023-09-20T12:59:02.064211Z","iopub.status.idle":"2023-09-20T12:59:33.346258Z","shell.execute_reply.started":"2023-09-20T12:59:02.064131Z","shell.execute_reply":"2023-09-20T12:59:33.345157Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"SVC()","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"precision_recall_fscore_svc_final, cm_final = validate_model(id_final, id_x_valid_pca_85, id_y_valid_cat)\n\nprint(\"Precision, Recall and F1 Score:\", precision_recall_fscore_svc_final)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T12:59:33.347780Z","iopub.execute_input":"2023-09-20T12:59:33.348256Z","iopub.status.idle":"2023-09-20T12:59:37.136790Z","shell.execute_reply.started":"2023-09-20T12:59:33.348211Z","shell.execute_reply":"2023-09-20T12:59:37.135928Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Accuracy:  0.9053333333333333\nConfusion matrix: \n[[11  0  0 ...  0  0  0]\n [ 0  9  0 ...  0  0  0]\n [ 0  0 10 ...  0  0  0]\n ...\n [ 0  0  0 ... 20  0  0]\n [ 0  0  0 ...  0 10  0]\n [ 0  0  0 ...  0  0  9]]\nPrecision, recall, f1-score: \nPrecision, Recall and F1 Score: (0.9180403130982078, 0.9053333333333333, 0.906750374001572, None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Hyperparameter Tuning SVC","metadata":{}},{"cell_type":"code","source":"id_grid = {\n    \"C\": [1, 10, 100, 1000],\n    \"gamma\": [0.1, 0.01, 0.001, 0.0001],\n    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n    \"degree\": [1, 2, 3, 4, 5],\n}\n\nid_rs_model = tune_hyperparameters(\n    {\"id_final\": SVC()}, id_grid, id_x_train_pca_85, id_x_valid_pca_85, id_y_train_cat, id_y_valid_cat\n)\n\nid_precision_recall_fscore_svc_final, id_cm_final = validate_model(id_rs_model[\"id_final\"].best_estimator_, id_x_valid_pca, id_y_valid_cat)\n\nprint(id_rs_model[\"id_final\"].best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T12:59:37.137923Z","iopub.execute_input":"2023-09-20T12:59:37.138667Z","iopub.status.idle":"2023-09-20T13:32:32.959614Z","shell.execute_reply.started":"2023-09-20T12:59:37.138633Z","shell.execute_reply":"2023-09-20T13:32:32.957805Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 8 candidates, totalling 40 fits\n[CV 1/5] END C=0.1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.7min\n[CV 5/5] END C=0.1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 2/5] END C=0.1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 1/5] END C=0.1, degree=2, gamma=0.01, kernel=rbf;, score=0.741 total time= 2.3min\n[CV 5/5] END C=0.1, degree=2, gamma=0.01, kernel=rbf;, score=0.734 total time= 2.4min\n[CV 4/5] END C=1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 2/5] END C=1, degree=1, gamma=0.01, kernel=rbf;, score=0.901 total time= 2.4min\n[CV 1/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 5/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 3/5] END C=0.1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 2/5] END C=0.1, degree=1, gamma=0.01, kernel=rbf;, score=0.737 total time= 2.4min\n[CV 1/5] END C=0.1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 5/5] END C=0.1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.7min\n[CV 4/5] END C=0.1, degree=2, gamma=0.01, kernel=rbf;, score=0.748 total time= 2.4min\n[CV 3/5] END C=1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 3/5] END C=1, degree=1, gamma=0.01, kernel=rbf;, score=0.901 total time= 2.3min\n[CV 5/5] END C=1, degree=1, gamma=0.01, kernel=rbf;, score=0.899 total time= 2.4min\n[CV 4/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 3/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.901 total time= 2.3min\n[CV 4/5] END C=0.1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 3/5] END C=0.1, degree=1, gamma=0.01, kernel=rbf;, score=0.742 total time= 2.4min\n[CV 4/5] END C=0.1, degree=1, gamma=0.01, kernel=rbf;, score=0.748 total time= 2.4min\n[CV 3/5] END C=0.1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 2/5] END C=0.1, degree=2, gamma=0.01, kernel=rbf;, score=0.737 total time= 2.3min\n[CV 1/5] END C=1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 5/5] END C=1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 2/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 1/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.900 total time= 2.3min\n[CV 4/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.892 total time= 2.2min\n[CV 2/5] END C=0.1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 1/5] END C=0.1, degree=1, gamma=0.01, kernel=rbf;, score=0.741 total time= 2.4min\n[CV 5/5] END C=0.1, degree=1, gamma=0.01, kernel=rbf;, score=0.734 total time= 2.4min\n[CV 4/5] END C=0.1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.8min\n[CV 3/5] END C=0.1, degree=2, gamma=0.01, kernel=rbf;, score=0.742 total time= 2.3min\n[CV 2/5] END C=1, degree=1, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 1/5] END C=1, degree=1, gamma=0.01, kernel=rbf;, score=0.900 total time= 2.4min\n[CV 4/5] END C=1, degree=1, gamma=0.01, kernel=rbf;, score=0.892 total time= 2.3min\n[CV 3/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.017 total time= 3.9min\n[CV 2/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.901 total time= 2.4min\n[CV 5/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.899 total time= 1.8min\n","output_type":"stream"}]},{"cell_type":"code","source":"id_label_1_final_preds = id_rs_model[\"id_final\"].best_estimator_.predict(id_x_test_pca_85)\npd.DataFrame(id_label_1_final_preds, columns=[\"label_1\"]).to_csv(\"id_label_1_final_preds.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label 2 - Age","metadata":{}},{"cell_type":"code","source":"# Handling NaN values in the age\n# Combine X and y into a single DataFrame\n\nage_data_train_cat = pd.concat([x_train_scaled, age_train], axis=1)\nage_data_valid_cat = pd.concat([x_valid_scaled, age_valid], axis=1)\n\n# Remove rows with null values\nage_data_cleaned_train_cat = age_data_train_cat.dropna()\nage_data_cleaned_valid_cat = age_data_valid_cat.dropna()\n\n# Separate X and y again\nage_x_train_cat = age_data_cleaned_train_cat.drop(columns=[\"label_2\"])\nage_y_train_cat = age_data_cleaned_train_cat[\"label_2\"]\nage_x_valid_cat = age_data_cleaned_valid_cat.drop(columns=[\"label_2\"])\nage_y_valid_cat = age_data_cleaned_valid_cat[\"label_2\"].to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_x_train_pca, age_x_valid_pca, age_n_components, age_pca_cat = do_pca(\n    age_x_train_cat, age_x_valid_cat, n_components=180\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_x_test_pca_85 = pd.DataFrame(\n    age_pca_cat.transform(id_x_test_cat),\n    columns=[\"feature_pca_\" + str(i) for i in range(1, age_n_components + 1)],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_final = SVC()\nage_final.fit(age_x_train_pca, age_y_train_cat)\n\nage_precision_recall_fscore_svc_final, age_cm_final = validate_model(age_final, age_x_valid_pca, age_y_valid_cat)\n\nprint(\"Precision, Recall and F1 Score:\", age_precision_recall_fscore_svc_final)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter tuning for svc\nage_final_models = {\n    \"age_SVC\": SVC(),\n}\n\nage_grid = {\n    \"C\": [1, 10, 100, 1000],\n    \"gamma\": [0.1, 0.01, 0.001, 0.0001],\n    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n    \"degree\": [1, 2, 3, 4, 5],\n}\n\nage_rs_model = tune_hyperparameters(\n    age_final_models, age_grid, age_x_train_pca, age_x_valid_pca, age_y_train_cat, age_y_valid_cat\n)\n\nage_precision_recall_fscore_svc_final, age_cm_final = validate_model(age_rs_model[\"age_SVC\"].best_estimator_, age_x_valid_pca, age_y_valid_cat)\n\n\nprint(age_rs_model[\"age_SVC\"].best_params_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_label_1_final_preds = age_rs_model[\"age_SVC\"].best_estimator_.predict(age_x_test_pca_85)\npd.DataFrame(age_label_1_final_preds, columns=[\"label_1\"]).to_csv(\"age_label_1_final_preds.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label 3 - Gender","metadata":{}},{"cell_type":"code","source":"# Handling NaN values in the age\n# Combine X and y into a single DataFrame\n\ngender_data_train_cat = pd.concat([x_train_scaled, gender_train], axis=1)\ngender_data_valid_cat = pd.concat([x_valid_scaled, gender_valid], axis=1)\n\n# Remove rows with null values\ngender_data_cleaned_train_cat = gender_data_train_cat.dropna()\ngender_data_cleaned_valid_cat = gender_data_valid_cat.dropna()\n\n# Separate X and y again\ngender_x_train_cat = gender_data_cleaned_train_cat.drop(columns=[\"label_3\"])\ngender_y_train_cat = gender_data_cleaned_train_cat[\"label_3\"]\ngender_x_valid_cat = gender_data_cleaned_valid_cat.drop(columns=[\"label_3\"])\ngender_y_valid_cat = gender_data_cleaned_valid_cat[\"label_3\"].to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_initial = SVC()\ngender_initial.fit(gender_x_train_cat, gender_y_train_cat)\n\ngender_precision_recall_fscore_svc_initial, gender_cm_initial = validate_model(gender_initial, gender_x_valid_cat, gender_y_valid_cat)\n\nprint(\"Precision, Recall and F1 Score:\", gender_precision_recall_fscore_svc_initial)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_x_train_pca, gender_x_valid_pca, gender_n_components, gender_pca_cat = do_pca(\n    gender_x_train_cat, gender_x_valid_cat, n_components=32\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_x_test_pca_85 = pd.DataFrame(\n    gender_pca_cat.transform(id_x_test_cat),\n    columns=[\"feature_pca_\" + str(i) for i in range(1, gender_n_components + 1)],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter tuning for svc\ngender_final_models = {\n    \"gender_SVC\": SVC(),\n}\n\ngender_grid = {\n    \"C\": [1, 10, 100, 1000],\n    \"gamma\": [0.1, 0.01, 0.001, 0.0001],\n    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n    \"degree\": [1, 2, 3, 4, 5],\n}\n\ngender_rs_model = tune_hyperparameters(\n    gender_final_models, gender_grid, gender_x_train_pca, gender_x_valid_pca, gender_y_train_cat, gender_y_valid_cat\n)\n\ngender_precision_recall_fscore_svc_final, gender_cm_final = validate_model(gender_rs_model[\"gender_SVC\"].best_estimator_, gender_x_valid_pca, gender_y_valid_cat)\n\n\nprint(gender_rs_model[\"gender_SVC\"].best_params_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_label_1_final_preds = age_rs_model[\"gender_SVC\"].best_estimator_.predict(gender_x_test_pca_85)\npd.DataFrame(gender_label_1_final_preds, columns=[\"label_1\"]).to_csv(\"gender_label_1_final_preds.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label 4","metadata":{}},{"cell_type":"code","source":"# Handling NaN values in the age\n# Combine X and y into a single DataFrame\n\naccent_data_train_cat = pd.concat([x_train_scaled, accent_train], axis=1)\naccent_data_valid_cat = pd.concat([x_valid_scaled, accent_valid], axis=1)\n\n# Remove rows with null values\naccent_data_cleaned_train_cat = accent_data_train_cat.dropna()\naccent_data_cleaned_valid_cat = accent_data_valid_cat.dropna()\n\n# Separate X and y again\naccent_x_train_cat = accent_data_cleaned_train_cat.drop(columns=[\"label_4\"])\naccent_y_train_cat = accent_data_cleaned_train_cat[\"label_4\"]\naccent_x_valid_cat = accent_data_cleaned_valid_cat.drop(columns=[\"label_4\"])\naccent_y_valid_cat = accent_data_cleaned_valid_cat[\"label_4\"].to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accent_initial = SVC()\naccent_initial.fit(accent_x_train_cat, accent_y_train_cat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accent_precision_recall_fscore_svc_initial, accent_cm_initial = validate_model(accent_initial, accent_x_valid_cat, accent_y_valid_cat)\n\nprint(\"Precision, Recall and F1 Score:\", accent_precision_recall_fscore_svc_initial)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accent_x_train_pca, accent_x_valid_pca, accent_n_components, accent_pca_cat = do_pca(\n    accent_x_train_cat, accent_x_valid_cat, n_components=130\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accent_x_test_pca_85 = pd.DataFrame(\n    accent_pca_cat.transform(id_x_test_cat),\n    columns=[\"feature_pca_\" + str(i) for i in range(1, accent_n_components + 1)],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter tuning for svc\naccent_final_models = {\n    \"accent_SVC\": SVC(),\n}\n\naccent_grid = {\n    \"C\": [1, 10, 100, 1000],\n    \"gamma\": [0.1, 0.01, 0.001, 0.0001],\n    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n    \"degree\": [1, 2, 3, 4, 5],\n}\n\n\naccent_rs_model = tune_hyperparameters(\n    accent_final_models, accent_grid, accent_x_train_pca, accent_x_valid_pca, accent_y_train_cat, accent_y_valid_cat\n)\n\naccent_precision_recall_fscore_svc_final, accent_cm_final = validate_model(accent_rs_model[\"accent_SVC\"].best_estimator_, accent_x_valid_pca, accent_y_valid_cat)\n\nprint(accent_rs_model[\"accent_SVC\"].best_params_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accent_label_1_final_preds = accent_rs_model[\"accent_SVC\"].best_estimator_.predict(accent_x_test_pca_85)\npd.DataFrame(accent_label_1_final_preds, columns=[\"label_1\"]).to_csv(\"accent_label_1_final_preds.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RESULTS","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}